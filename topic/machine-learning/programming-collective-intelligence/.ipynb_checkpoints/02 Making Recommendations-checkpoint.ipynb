{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics = {\n",
    "    'Lisa Rose': {\n",
    "        'Lady in the Water': 2.5, \n",
    "        'Snakes on a Plane': 3.5, \n",
    "        'Just My Luck': 3.0, \n",
    "        'Superman Returns': 3.5, \n",
    "        'You, Me and Dupree': 2.5, \n",
    "        'The Night Listener': 3.0\n",
    "    },\n",
    "    'Gene Seymour': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 1.5,\n",
    "        'Superman Returns': 5.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 3.5, \n",
    "    },\n",
    "    'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0,\n",
    "    },\n",
    "    'Claudia Puig': {\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'The Night Listener': 4.5,\n",
    "        'Superman Returns': 4.0,\n",
    "        'You, Me and Dupree': 2.5, \n",
    "    },\n",
    "    'Mick LaSalle': {\n",
    "        'Lady in the Water': 3.0, \n",
    "        'Snakes on a Plane': 4.0, \n",
    "        'Just My Luck': 2.0, \n",
    "        'Superman Returns': 3.0, \n",
    "        'You, Me and Dupree': 2.0, \n",
    "        'The Night Listener': 3.0\n",
    "    },\n",
    "    'Jack Matthews': {\n",
    "        'Lady in the Water': 3.0, \n",
    "        'Snakes on a Plane': 4.0, \n",
    "        'Superman Returns': 5.0, \n",
    "        'You, Me and Dupree': 3.5, \n",
    "        'The Night Listener': 3.0\n",
    "    },\n",
    "    'Toby': {\n",
    "        'Snakes on a Plane': 4.5, \n",
    "        'Superman Returns': 4.0, \n",
    "        'You, Me and Dupree': 1.0\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance Score\n",
    "\n",
    "The sum of squares will return a value which will be smaller for people who are more similar. Since we need the inverse, where we want a higher value if they are similar we can do the ff:\n",
    "\n",
    "```python\n",
    "1 / (1 + sqrt(pow(5-4, 2) + pow(4-1, 2))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14814814814814814"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Returns a distance-based similarity score for person1 and person2\n",
    "def sim_distance(prefs, person1, person2):\n",
    "    # Get the list of shared_items\n",
    "    si={}\n",
    "    for item in prefs[person1]:\n",
    "        if item in prefs[person2]:\n",
    "            si[item]=1\n",
    "            \n",
    "    # if they have no ratings in common return 0\n",
    "    if len(si)==0: return 0\n",
    "    \n",
    "    # Add up the squares of all the diff\n",
    "    sum_of_squares = sum([pow(prefs[person1][item] - prefs[person2][item], 2)\n",
    "                         for item in prefs[person1] if item in prefs[person2]])\n",
    "    \n",
    "    return 1 / (1 + sum_of_squares)\n",
    "\n",
    "sim_distance(critics, 'Lisa Rose', 'Gene Seymour') # similarity score between Lisa Rose and Gene Seymour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Score\n",
    "\n",
    "The correlation coefficient is a measure of how well two sets of data fit on a straight line.\n",
    "\n",
    "`Best fit` line.\n",
    "\n",
    "One interesting aspect of using Pearson score, is that it corrects for `grade inflation`.\n",
    "\n",
    "If one critic is inclined to give higher scrores than the other, there can still be perfect correlation if the difference between their score is consistent.\n",
    "\n",
    "The difference with `Euclidian distance` score is that it will say that two critics are dissimilar because one is consistently harsher than the other, even if their tastes are very similar.\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Find the items rated by both critics.\n",
    "- Calculate the sums and sum of the squares of the ratings for the two critics and calculates the sum of the products of their ratings.\n",
    "- Finally, use these result to calculate the Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39605901719066977"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns the Pearson correlation coefficient for p1 and p2\n",
    "def sim_pearson(prefs, p1, p2):\n",
    "    # get the list of mutually rated items\n",
    "    si = {}\n",
    "    for item in prefs[p1]:\n",
    "        if item in prefs[p2]: si[item]=1\n",
    "            \n",
    "    # find the number of elements\n",
    "    n = len(si)\n",
    "    \n",
    "    # if they have no common rated movies, return 0\n",
    "    if n==0: return 0\n",
    "    \n",
    "    # add up all the preferences\n",
    "    sum1 = sum([prefs[p1][it] for it in si]) \n",
    "    sum2 = sum([prefs[p2][it] for it in si])\n",
    "    \n",
    "    # sum up the squares\n",
    "    sum1Sq = sum([pow(prefs[p1][it], 2) for it in si])\n",
    "    sum2Sq = sum([pow(prefs[p2][it], 2) for it in si])\n",
    "    \n",
    "    # sum up the products\n",
    "    pSum = sum([prefs[p1][it] * prefs[p2][it] for it in si])\n",
    "    \n",
    "    num = pSum - (sum1 * sum2 / n)\n",
    "    den = sqrt((sum1Sq - pow(sum1, 2) / n) * (sum2Sq - pow(sum2, 2) / n))\n",
    "    if den == 0: return 0\n",
    "    \n",
    "    r = num / den\n",
    "    \n",
    "    return r\n",
    "\n",
    "sim_pearson(critics, 'Lisa Rose', 'Gene Seymour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other similary metrics\n",
    "\n",
    "- Jaccard coefficient\n",
    "- Manhattan distance\n",
    "\n",
    "https://en.wikipedia.org/wiki/Metric_%28mathematics%29#Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sim_pearson' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cc1a9af1ce9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ranking the critis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtopMatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msim_pearson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     scores = [(similarity(prefs, person, other), other) \n\u001b[1;32m      5\u001b[0m                 for other in prefs if other != person]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sim_pearson' is not defined"
     ]
    }
   ],
   "source": [
    "# Ranking the critis\n",
    "\n",
    "def topMatches(prefs, person, n=5, similarity=sim_pearson):\n",
    "    scores = [(similarity(prefs, person, other), other) \n",
    "                for other in prefs if other != person]\n",
    "    \n",
    "    # sort the list so the highest scores appear at the top\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n]\n",
    "\n",
    "topMatches(critics, 'Toby', n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommending Items\n",
    "\n",
    "To recommend items, we need to score the items by producing a weighted score that ranks the critics. **Take the votes of all the other critics and multiply** how similar they are to me by the score they gave each movie.\n",
    "\n",
    "We need to get the similarity by movie, we need to regard more the score of the critic that we more similar.\n",
    "\n",
    "We need to get the sum of all these products and divide it with the **sum of all similarities**. We divide it with the **sum of similarities** instead of just the number of critics to remove the advantage of having more critics for a certain movie.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.3477895267131017, 'The Night Listener'),\n",
       " (2.8325499182641614, 'Lady in the Water'),\n",
       " (2.530980703765565, 'Just My Luck')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets the recommendations for a person by using a weighted average\n",
    "# of every other user's rankings\n",
    "def getRecommendations(prefs, person, similarity=sim_pearson):\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    for other in prefs:\n",
    "        # don't compare me to myself\n",
    "        if other == person: continue\n",
    "        sim = similarity(prefs, person, other)\n",
    "        \n",
    "        # ignore scors of zero or lower\n",
    "        if sim <= 0: continue\n",
    "            \n",
    "        for item in prefs[other]:\n",
    "            # only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # similarity * score\n",
    "                totals.setdefault(item, 0)\n",
    "                totals[item] += prefs[other][item] * sim\n",
    "                \n",
    "                # sum of similarities\n",
    "                simSums.setdefault(item, 0)\n",
    "                simSums[item] += sim\n",
    "                \n",
    "    rankings = [(total / simSums[item], item) for item, total in totals.items()]\n",
    "\n",
    "    # return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings\n",
    "\n",
    "getRecommendations(critics, 'Toby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Products\n",
    "\n",
    "You can determine similarity by looking at who liked a particular item and seeing the other things they liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topMatches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-abfb7cc408b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformPrefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtopMatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Superman Returns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'topMatches' is not defined"
     ]
    }
   ],
   "source": [
    "def transformPrefs(prefs):\n",
    "    result = {}\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:\n",
    "            # will set the value of key to value\n",
    "            result.setdefault(item, {})\n",
    "            \n",
    "            # Flip item and person\n",
    "            result[item][person] = prefs[person][item]\n",
    "    return result\n",
    "\n",
    "movies = transformPrefs(critics)\n",
    "topMatches(movies, 'Superman Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
